{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-beb55f24d5ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1229],\n",
      "        [ 0.1073],\n",
      "        [-1.6773],\n",
      "        [-0.5879]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自动求导机制"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4584],\n",
      "        [-0.3360],\n",
      "        [-1.5700],\n",
      "        [ 1.2315]], requires_grad=True)\n",
      "tensor([[ 1.3946],\n",
      "        [ 1.1711],\n",
      "        [ 0.4335],\n",
      "        [-1.7343]], requires_grad=True)\n",
      "tensor([[-0.2596,  0.1183,  0.2440,  1.1646],\n",
      "        [ 0.2886,  0.3866, -0.2011, -0.1179],\n",
      "        [ 0.1922, -0.7722, -1.9003,  0.1307],\n",
      "        [-0.7043,  0.3147,  0.1574,  0.3854]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,1, requires_grad=True)\n",
    "y = torch.randn(4,1, requires_grad=True)\n",
    "W = torch.randn(4,4)\n",
    "print(x)\n",
    "print(y)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8064, grad_fn=<TraceBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.trace(W.mm(y).t().mm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9798, -0.4458,  0.7732,  0.5564],\n",
       "        [ 0.7182, -0.3268,  0.5667,  0.4078],\n",
       "        [ 3.3558, -1.5269,  2.6481,  1.9056],\n",
       "        [-2.6323,  1.1977, -2.0771, -1.4947]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mm(W.mm(y).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.trace(x.mm(W.mm(y).t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $z = x^T W y $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3186]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = torch.mm(torch.mm(torch.t(x), W),y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3186]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "z = x.t().mm(W).mm(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8995],\n",
      "        [-1.0417],\n",
      "        [-0.3020],\n",
      "        [ 0.4710]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8995],\n",
      "        [-1.0417],\n",
      "        [-0.3020],\n",
      "        [ 0.4710]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(W.mm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3102],\n",
      "        [-0.3058],\n",
      "        [ 1.7528],\n",
      "        [ 0.0732]])\n"
     ]
    }
   ],
   "source": [
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3102],\n",
      "        [-0.3058],\n",
      "        [ 1.7528],\n",
      "        [ 0.0732]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(W.t().mm(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 默认情况下，定义的tensor属性requires_grad为false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2129],\n",
      "        [-0.6779],\n",
      "        [ 1.8371],\n",
      "        [-0.1568]], requires_grad=True)\n",
      "tensor([[5.3301]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,1, requires_grad=True)\n",
    "print(x)\n",
    "y = torch.mm(torch.t(x),x)\n",
    "print(y)\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4259],\n",
      "        [-1.3558],\n",
      "        [ 3.6741],\n",
      "        [-0.3135]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.3301]], grad_fn=<MmBackward>)\n",
      "tensor([[ 2.4259],\n",
      "        [-1.3558],\n",
      "        [ 3.6741],\n",
      "        [-0.3135]])\n",
      "tensor([[ 2.4259],\n",
      "        [-1.3558],\n",
      "        [ 3.6741],\n",
      "        [-0.3135]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(y)\n",
    "\n",
    "print(x.grad)\n",
    "\n",
    "print(2*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 给定数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
      "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
      "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
      "        [-0.5181, -0.3067, -1.5810,  1.7066]])\n",
      "tensor([[ 1.5091,  2.0820,  1.7067,  2.3804],\n",
      "        [-1.1256, -0.3170, -1.0925, -0.0852],\n",
      "        [ 0.3276, -0.7607, -1.5991,  0.0185],\n",
      "        [-0.7504,  0.1854,  0.6211,  0.6382],\n",
      "        [-0.0033, -0.5344,  1.1687,  0.3945],\n",
      "        [ 1.9415,  0.7915, -0.0203, -0.4372],\n",
      "        [-0.2188, -2.4351, -0.0729, -0.0340],\n",
      "        [ 0.9625,  0.3492, -0.9215, -0.0562],\n",
      "        [-0.6227, -0.4637,  1.9218, -0.4025],\n",
      "        [ 0.1239,  1.1648,  0.9234,  1.3873]], requires_grad=True)\n",
      "tensor([[ 0.2055, -0.4503, -0.5731, -0.5554],\n",
      "        [ 0.5943,  1.5419,  0.5073, -0.5910],\n",
      "        [-1.3253,  0.1886, -0.0691, -0.4949],\n",
      "        [-1.4959, -0.1938,  0.4455,  1.3253]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "\n",
    "x = torch.randn(10,4)\n",
    "W = torch.randn(4,4)\n",
    "y = torch.randn(10,4, requires_grad=True)\n",
    "\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标函数 $f = ||max(XW,0)-Y||^2_F $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $f = ||\\hat{Y}-Y||^2_F $; $\\hat{Y} = max(Z,0)$; $Z = XW$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = (torch.clamp(x.mm(W), 0) - y).pow(2).sum()    #clamp 将范围统一到（min,max）之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x.mm(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = torch.clamp(z, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = (y_hat - y).pow(2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99.9048, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(99.9048, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# W.grad.zero_()\n",
    "print(W.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor([[ 2.8885e+00,  4.1639e+00,  3.4134e+00,  3.0501e+00],\n",
      "        [-1.0589e+01, -2.7045e+00, -2.1849e+00, -1.7039e-01],\n",
      "        [ 6.5523e-01, -1.5214e+00, -3.1982e+00, -1.5687e+00],\n",
      "        [-1.5009e+00, -3.8551e+00,  4.9843e-01,  1.2764e+00],\n",
      "        [-6.6077e-03, -1.0689e+00,  1.8791e+00, -4.2604e+00],\n",
      "        [ 3.8829e+00,  1.5830e+00, -4.0504e-02, -7.2968e+00],\n",
      "        [-4.3767e-01, -4.8701e+00, -1.4583e-01, -1.3166e+00],\n",
      "        [ 1.9250e+00,  6.9834e-01, -1.8429e+00, -1.4750e+00],\n",
      "        [-5.0359e+00, -9.2744e-01,  3.8436e+00, -8.0509e-01],\n",
      "        [ 2.4780e-01,  2.3296e+00, -1.7491e-01, -4.2519e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(W.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 公式推导求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "y_hat_grad = -2 * (y_hat - y)\n",
    "y_grad_gt = y.grad\n",
    "# print(y_hat_grad)\n",
    "print(torch.equal(y_hat_grad, y_grad_gt))\n",
    "# print(y_hat_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_grad = \n",
    "\n",
    "# print(z_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 18.2980,   2.7573,   2.3914,  -0.1974],\n",
      "        [ 11.0817,   6.6428,   2.5163, -20.3225],\n",
      "        [ -8.6662,   3.4506,  -1.8979,  -3.3608],\n",
      "        [-21.1681,  -6.6739,  -1.0693,  27.0278]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "W_grad = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Tensor 与 Numpy 转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "a = np.random.randn(3,4)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tensor = torch.from_numpy(a)\n",
    "print(a_tensor)\n",
    "print(type(a_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a_tensor.numpy()\n",
    "print(b)\n",
    "print(type(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor = torch.randn(3, 4, requires_grad=False)\n",
    "d_numpy = d_tensor.numpy()\n",
    "print(d_numpy)\n",
    "print(type(d_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor = torch.randn(3, 4, requires_grad=True)\n",
    "d_numpy = d_tensor.numpy()\n",
    "print(d_numpy)\n",
    "print(type(d_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tensor = torch.randn(3, 4, requires_grad=True)\n",
    "d_numpy = d_tensor.data.numpy()\n",
    "print(d_numpy)\n",
    "print(d_tensor.data)\n",
    "print(type(d_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mps')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d2a7cdaa3147cfe62b452d20213d10d6c9fced858ab295933fec9aa2167f343"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
